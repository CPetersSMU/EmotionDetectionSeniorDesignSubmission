{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first draft where the goal will be to have the preprocessor feed the trained neural network a face, and for an output to be given. The user should be able to take a picture and get a reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Import Block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import roc_curve\n",
    "from skimage.io import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import auc\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "\n",
    "#print entire array\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Faces Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('faces.csv')\n",
    "#df = df.drop(columns=['Usage'])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Limit the categories to just happy, sad, neutral, and prepare data\n",
    "#label_to_hr = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}\n",
    "#0: anger\n",
    "#1: disgust (almost no entries)\n",
    "#2: fear (not as many, getting confused with sadness)\n",
    "#3: happiness\n",
    "#4: sadness\n",
    "#5: surprise\n",
    "#6: neutral\n",
    "LabelsOfInterest = [3, 4, 5] # happy, sad, surprised\n",
    "\n",
    "NUM_CLASSES = len(LabelsOfInterest)\n",
    "df = df[df.emotion.isin(LabelsOfInterest)]\n",
    "print(df.head())\n",
    "img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48, 1).astype('float32'))\n",
    "img_array = np.stack(img_array, axis=0)\n",
    "le = LabelEncoder()\n",
    "img_labels = le.fit_transform(df.emotion)\n",
    "img_labels = np_utils.to_categorical(img_labels)\n",
    "img_labels.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_array, img_labels,\n",
    "                                                    shuffle=True, stratify=img_labels,\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]\n",
    "img_depth = X_train.shape[3]\n",
    "num_classes = y_train.shape[1]\n",
    "X_train = (X_train/255)-0.5\n",
    "X_test = (X_test/255)-0.5\n",
    "X_test.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Chosen Architecture: Use two convolution layers\n",
    "l2_lambda = 0.0001\n",
    "cnn = Sequential() \n",
    "\n",
    "cnn.add( Conv2D(filters=32, \n",
    "                kernel_size= (3, 3),\n",
    "                kernel_initializer='he_uniform', \n",
    "                kernel_regularizer=l2(l2_lambda),\n",
    "                padding='same', \n",
    "                input_shape=(img_width, img_height, img_depth),\n",
    "                activation='relu',\n",
    "                data_format=\"channels_last\") )\n",
    "\n",
    "# cnn.add( MaxPooling2D(pool_size=(2, 2), \n",
    "#                 data_format=\"channels_last\") )\n",
    "\n",
    "cnn.add( Conv2D(filters=32, \n",
    "                kernel_size= (3, 3),\n",
    "                kernel_initializer='he_uniform', \n",
    "                kernel_regularizer=l2(l2_lambda),\n",
    "                padding='same', \n",
    "                input_shape=(img_width, img_height, img_depth),\n",
    "                activation='relu',\n",
    "                data_format=\"channels_last\") )\n",
    "\n",
    "cnn.add( MaxPooling2D(pool_size=(2, 2), \n",
    "                data_format=\"channels_last\") )\n",
    "\n",
    "cnn.add( Conv2D(filters=64, \n",
    "                kernel_size= (3, 3),\n",
    "                kernel_initializer='he_uniform', \n",
    "                kernel_regularizer=l2(l2_lambda),\n",
    "                padding='same', \n",
    "                input_shape=(img_width, img_height, img_depth),\n",
    "                activation='relu',\n",
    "                data_format=\"channels_last\") )\n",
    "\n",
    "# cnn.add( MaxPooling2D(pool_size=(2, 2), \n",
    "#                 data_format=\"channels_last\") )\n",
    "\n",
    "cnn.add( Conv2D(filters=64, \n",
    "                kernel_size= (3, 3),\n",
    "                kernel_initializer='he_uniform', \n",
    "                kernel_regularizer=l2(l2_lambda),\n",
    "                padding='same', \n",
    "                input_shape=(img_width, img_height, img_depth),\n",
    "                activation='relu',\n",
    "                data_format=\"channels_last\") )\n",
    "\n",
    "cnn.add( MaxPooling2D(pool_size=(2, 2), \n",
    "                data_format=\"channels_last\") )\n",
    "\n",
    "cnn.add(Conv2D(filters=128,\n",
    "               input_shape=(img_width, img_height, img_depth),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu',data_format=\"channels_last\")) # more compact syntax\n",
    "\n",
    "cnn.add(Conv2D(filters=128,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu',data_format=\"channels_last\"))\n",
    "\n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn.add( Flatten() )\n",
    "cnn.add(Dropout(0.25))\n",
    "cnn.add(Dense(128, \n",
    "              activation='relu',\n",
    "              kernel_initializer='he_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda) ))\n",
    "\n",
    "cnn.add( Dense(NUM_CLASSES) )\n",
    "cnn.add( Activation('softmax') )\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Let's train the model \n",
    "cnn.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = cnn.fit(X_train, y_train, \n",
    "        batch_size=32, epochs=50,\n",
    "        shuffle=True, verbose=1,\n",
    "        validation_data=(X_test,y_test),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "cnn.save('cnn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessor\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread(\"TestEmotions/input_happy.jpg\")\n",
    "displayImg = cv2.resize(img, (495, 660))\n",
    "cv2.imshow(\"Show\", displayImg)\n",
    "#cv2.waitKey(0)\n",
    "print('2')\n",
    "faces = faceCascade.detectMultiScale(img,1.1,4)\n",
    "facePics =[]\n",
    "facePics.clear()\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h), (0,255,0),2)\n",
    "    tempface = img[y:y+h, x:x+w]\n",
    "    facePics.append(tempface)\n",
    "imgResize = cv2.resize(facePics[0],(48,48))\n",
    "imgGray = cv2.cvtColor(imgResize, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Show\", imgGray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Image Shape: \" + str(imgGray.shape))\n",
    "print(\"NetInput Image Shape: \" + str(X_test.shape))\n",
    "reshapeImg = imgGray.reshape((1,48,48,1))\n",
    "print(\"Working Image Shape:  \" + str(reshapeImg.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedImg = (reshapeImg - np.amin(reshapeImg)) / (np.amax(reshapeImg) - np.amin(reshapeImg))\n",
    "normalizedImg = 2*normalizedImg-1 #s\n",
    "print(\"0 is Anger, 1 is Afraid, 2 is Happy, 3 is Sad\")\n",
    "yhat_cnn = np.argmax(cnn.predict(normalizedImg), axis=1)\n",
    "print(yhat_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(cnn, X_test, y_test):\n",
    "    yhat_cnn = np.argmax(cnn.predict(X_test), axis=1)\n",
    "    print(yhat_cnn)\n",
    "    acc_cnn = mt.accuracy_score(np.argmax(y_test, axis=1),yhat_cnn)\n",
    "    cm = mt.confusion_matrix(np.argmax(y_test, axis=1),yhat_cnn)\n",
    "    cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f')\n",
    "    plt.title('Results: '+str(acc_cnn))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(cnn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
